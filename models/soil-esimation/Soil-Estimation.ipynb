{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction\n",
    "How to open and understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Earth_Observation/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from time import  time_ns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic information\n",
    "1. Hyperspectral data:\n",
    "    1. `hsi_path` contains path to hyperspectral masked numpy arrays containing hyperspectral data that underwent masking (i.e., the field area is masked, whereas all irrelevant areas are not masked)\n",
    "    2. The name of the file (e.g., _'1989.npz'_) refers to the index of the corresponding training sample in the ground-truth table.\n",
    "2. Ground-truth data:\n",
    "    1. `gt_path` contains path to ground truth .csv file.\n",
    "    2. Additionally, `wavelength_path` contains the mapping between a band number and the corresponding wavelength.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/mnt/SoilEstimation/\"\n",
    "\n",
    "hsi_path = base_path + 'train_data/1570.npz'\n",
    "gt_path = base_path + 'train_gt.csv'\n",
    "wavelength_path = base_path + 'wavelengths.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_AdamW = True # Flag utilized for switching between AdamW and SGD optimizer.\n",
    "\n",
    "if use_AdamW:\n",
    "  config = {'train_test_split':0.1, # train test split ratio\n",
    "            'tr_val_split':0.2, # train validation split ratio\n",
    "            'seed':42, # random seed\n",
    "            'mini_batch_size':128,\n",
    "            'epochs':75,\n",
    "            \n",
    "            # Settings for the optimizer AdamW\n",
    "            'lr':5e-4, # learning rate\n",
    "            'weight_decay':5e-4,\n",
    "\n",
    "            # Settings for the lr_scheduler CosineAnnealingWarmRestarts\n",
    "            't_0':5, # Number of iterations for the first restart.\n",
    "            'eta_min':1e-5, # Minimum learning rate\n",
    "          }\n",
    "else:\n",
    "  config = {'train_test_split':0.1, # train test split ratio\n",
    "            'tr_val_split':0.2, # train validation split ratio\n",
    "            'seed':42, # random seed\n",
    "            'mini_batch_size':128,\n",
    "            'epochs':100,\n",
    "\n",
    "            # Settings for the optimizer SGD\n",
    "            'lr':1e-4, # learning rate\n",
    "            'weight_decay':5e-4,  \n",
    "            'momentum':0.9,\n",
    "\n",
    "            # Settings for the lr_scheduler MultiStepLR\n",
    "            'milestones':[50,75,90], # List of epoch indices.\n",
    "            'gamma':0.2, # Multiplicative factor of learning rate decay.\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=42):\n",
    "    random.seed(seed) # set python seed\n",
    "    np.random.seed(seed) # seed the global NumPy random number generator(RNG)\n",
    "    torch.manual_seed(seed) # seed the RNG for all devices(both CPU and CUDA) \n",
    "\n",
    "set_random_seed(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv(gt_path)\n",
    "wavelength_df = pd.read_csv(wavelength_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 4\n",
    "model101_path=\"./model101\"\n",
    "model50_path=\"./model50\"\n",
    "\n",
    "# https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html\n",
    "#model = models.resnet50(weights=\"DEFAULT\")\n",
    "model101 = models.resnet101(weights=None)\n",
    "model101.fc = nn.Linear(model101.fc.in_features, num_classes)\n",
    "model101.to(device)\n",
    "\n",
    "model50 = models.resnet50(weights=None)\n",
    "model50.fc = nn.Linear(model50.fc.in_features, num_classes)\n",
    "model50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "def load_data(directory: str):\n",
    "    \"\"\"Load each cube, reduce its dimensionality and append to array.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory to either train or test set\n",
    "    Returns:\n",
    "        [type]: A list with spectral curve for each sample.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    all_files = np.array(\n",
    "        sorted(\n",
    "            glob(os.path.join(directory, \"*.npz\")),\n",
    "            key=lambda x: int(os.path.basename(x).replace(\".npz\", \"\")),\n",
    "        )\n",
    "    )\n",
    "    for file_name in all_files:\n",
    "        with np.load(file_name) as npz:\n",
    "            \n",
    "            arr = npz['data'][[0,75,-1],:,:]\n",
    "            mask = npz[\"mask\"][[0,75,-1],:,:]\n",
    "\n",
    "            # arr = npz['data']\n",
    "            # mask = npz[\"mask\"]\n",
    "\n",
    "            \n",
    "            arr = torch.tensor(arr, dtype=torch.float32)\n",
    "            mask = torch.tensor(~mask, dtype=torch.float32)\n",
    "            \n",
    "            transformer = transforms.Resize((128,128), antialias=True)\n",
    "\n",
    "            arr = transformer(arr)\n",
    "            mask = transformer(mask)\n",
    "\n",
    "            arr = arr * mask\n",
    "            \n",
    "        #arr = filtering(arr)\n",
    "        data.append(arr)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_gt(file_path: str):\n",
    "    \"\"\"Load labels for train set from the ground truth file.\n",
    "    Args:\n",
    "        file_path (str): Path to the ground truth .csv file.\n",
    "    Returns:\n",
    "        [type]: 2D numpy array with soil properties levels\n",
    "    \"\"\"\n",
    "    gt_file = pd.read_csv(file_path)\n",
    "    labels = gt_file[[\"P\", \"K\", \"Mg\", \"pH\"]].values\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_data(base_path + \"train_data\")\n",
    "y_train = load_gt(base_path + \"train_gt.csv\")\n",
    "X_test = load_data(base_path + \"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1732, 3, 128, 128])\n",
      "torch.Size([1732, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_x = torch.stack(X_train)\n",
    "tensor_y = torch.Tensor(y_train)\n",
    "\n",
    "batch_size = tensor_x.size(0)\n",
    "\n",
    "print(tensor_x.shape)\n",
    "print(tensor_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset=TensorDataset(tensor_x,tensor_y)\n",
    "\n",
    "n = int(len(tensor_x) * config['tr_val_split'])\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [n, len(dataset) - n])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=32,shuffle=True) \n",
    "\n",
    "test_x = torch.stack(X_test)\n",
    "testset=TensorDataset(test_x)\n",
    "\n",
    "test_dataloader= DataLoader(testset,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer):\n",
    "    running_loss = 0.\n",
    "    num_samples = 0\n",
    "\n",
    "    for _, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.to(device))\n",
    "        \n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        num_samples += inputs.size(0)\n",
    "        \n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "def train(model,path):\n",
    "        # Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = SummaryWriter('./eurosat_trainer_{}'.format(timestamp))\n",
    "    epoch_number = 0\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    if use_AdamW: \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'], momentum=config['momentum'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        print('============= EPOCH {} ============='.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(model,optimizer)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "\n",
    "        # Set the model to evaluation mode, disabling dropout and using population statistics for batch normalization.\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_dataloader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs.to(device))\n",
    "                vloss = criterion(voutputs, vlabels.to(device))\n",
    "                running_vloss += vloss\n",
    "                _, vpredictions = voutputs.max(dim=-1)\n",
    "\n",
    "        avg_vloss = running_vloss / len(val_dataloader)\n",
    "        print('LOSS : train {} | valid {}'.format(round(avg_loss, 4), round(avg_vloss.item(), 4)))\n",
    "\n",
    "        # Log the running loss averaged per epoch for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(model.state_dict(), path)\n",
    "\n",
    "        epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knowledge_distillation_regression(teacher, student, T, soft_target_loss_weight, ce_loss_weight, device, student_path):\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(student.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    teacher.eval()  # Teacher set to evaluation mode\n",
    "\n",
    "    best_vloss = float('inf')  # Set the best validation loss to infinity\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        student.train()  # Student to train mode\n",
    "\n",
    "        print('============= EPOCH {} ============='.format(epoch + 1))\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_vloss = 0.0\n",
    "\n",
    "        for _, data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            soft_targets = teacher_logits / T\n",
    "            soft_prob = student_logits / T\n",
    "\n",
    "            # Calculate the soft targets loss. No need to scale by T**2 for regression.\n",
    "            soft_targets_loss = mse_loss(soft_prob, soft_targets)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = mse_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "        # Set the model to evaluation mode, disabling dropout and using population statistics for batch normalization.\n",
    "        student.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_dataloader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = student(vinputs.to(device))\n",
    "                vloss = mse_loss(voutputs, vlabels.to(device))\n",
    "                running_vloss += vloss.item()\n",
    "\n",
    "        avg_vloss = running_vloss / len(val_dataloader)\n",
    "        print('LOSS : train {} | valid {}'.format(round(avg_loss, 4), round(avg_vloss, 4)))\n",
    "\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(student.state_dict(), student_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def size(path):\n",
    "    return os.path.getsize(path) / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,path):\n",
    "    model.eval()\n",
    "    predictions = []  # Inizializza una lista per memorizzare le predizioni\n",
    "    start = time_ns()\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(test_dataloader):\n",
    "            inputs = data[0].to(device)\n",
    "            # Effettua le previsioni utilizzando il modello\n",
    "            outputs = model(inputs)\n",
    "            # Aggiungi le predizioni alla lista delle predizioni\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "    time = time_ns()-start\n",
    "\n",
    "    predictions_array = np.concatenate(predictions)\n",
    "    submission_df = pd.DataFrame(data=predictions_array, columns=[\"P\", \"K\", \"Mg\", \"pH\"])\n",
    "    submission_df.to_csv(path, index_label=\"sample_index\")\n",
    "\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(model101,model101_path)\n",
    "# train(model50,model50_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "baseline_model = models.resnet101(weights=None)\n",
    "baseline_model.fc = nn.Linear(baseline_model.fc.in_features, num_classes)\n",
    "baseline_model.load_state_dict(torch.load(model101_path))\n",
    "baseline_model.to(device)\n",
    "\n",
    "\n",
    "### 1.35955\n",
    "baseline_time = predict(baseline_model, \"baseline_submission.csv\")\n",
    "baseline_size = size(model101_path)\n",
    "baseline_parameters = count_parameters(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model:\n",
      " - has 100.00% of parameters\n",
      " - is 1.00 times smaller\n",
      " - is 1.15 times faster\n"
     ]
    }
   ],
   "source": [
    "pruned_model = models.resnet101(weights=None)\n",
    "pruned_model.fc = nn.Linear(pruned_model.fc.in_features, num_classes)\n",
    "pruned_model.load_state_dict(torch.load(model101_path))\n",
    "pruned_model.to(device)\n",
    "pruned_model.eval()\n",
    "\n",
    "pruned_path = \"./pruned_model_0_2\"\n",
    "\n",
    "parameters_to_prune = []\n",
    "for module_name, module in pruned_model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        parameters_to_prune.append((module, \"weight\"))\n",
    "\n",
    "parameters_to_prune.append((pruned_model.fc,\"weight\"))\n",
    "\n",
    "## send pruning 0.5\n",
    "# The pruned model:\n",
    "#  - has 100.00% of parameters\n",
    "#  - is 1.00 times smaller\n",
    "#  - is 1.01 times faster\n",
    "\n",
    "## to send pruning 0.4\n",
    "# The pruned model:\n",
    "#  - has 100.00% of parameters\n",
    "#  - is 1.00 times smaller\n",
    "#  - is 1.02 times faster\n",
    "\n",
    "## to send pruning 0.3\n",
    "# The pruned model:\n",
    "#  - has 100.00% of parameters\n",
    "#  - is 1.00 times smaller\n",
    "#  - is 0.96 times faster\n",
    "\n",
    "## to send pruning 0.2\n",
    "# The pruned model:\n",
    "#  - has 100.00% of parameters\n",
    "#  - is 1.00 times smaller\n",
    "#  - is 1.15 times faster\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.4\n",
    ")\n",
    "\n",
    "for module,name in parameters_to_prune:\n",
    "    prune.remove(module,name)\n",
    "\n",
    "torch.save(pruned_model.state_dict(), pruned_path)\n",
    "\n",
    "pruned_time = predict(pruned_model, \"pruned_submission_0_2.csv\")\n",
    "pruned_size = size(pruned_path)\n",
    "pruned_parameters = count_parameters(pruned_model)\n",
    "\n",
    "print(f\"The pruned model:\") \n",
    "print(f\" - has {(pruned_parameters/baseline_parameters)*100:.2f}% of parameters\")\n",
    "print(f\" - is {baseline_size/pruned_size:.2f} times smaller\")\n",
    "print(f\" - is {baseline_time/pruned_time:.2f} times faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The small model:\n",
      " - has 55.32% of parameters\n",
      " - is 1.81 times smaller\n",
      " - is 1.69 times faster\n",
      "The student model:\n",
      " - has 55.32% of parameters\n",
      " - is 1.81 times smaller\n",
      " - is 1.49 times faster\n"
     ]
    }
   ],
   "source": [
    "teacher_model = models.resnet101(weights=None)\n",
    "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, num_classes)\n",
    "teacher_model.load_state_dict(torch.load(model101_path))\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()\n",
    "\n",
    "small_model = models.resnet50(weights=None)\n",
    "small_model.fc = nn.Linear(small_model.fc.in_features, num_classes)\n",
    "small_model.load_state_dict(torch.load(model50_path))\n",
    "small_model.to(device)\n",
    "small_model.eval()\n",
    "\n",
    "student_path = \"./student_model\"\n",
    "student_model = models.resnet50(weights=None)\n",
    "student_model.fc = nn.Linear(student_model.fc.in_features, num_classes)\n",
    "student_model.to(device)\n",
    "\n",
    "#train_knowledge_distillation_regression(teacher=teacher_model, student=student_model, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device,student_path=student_path)\n",
    "student_model.load_state_dict(torch.load(student_path))\n",
    "\n",
    "small_time = predict(small_model, \"small_submission.csv\")\n",
    "small_size = size(model50_path)\n",
    "small_parameters = count_parameters(small_model)\n",
    "print(f\"The small model:\") \n",
    "print(f\" - has {(small_parameters/baseline_parameters)*100:.2f}% of parameters\")\n",
    "print(f\" - is {baseline_size/small_size:.2f} times smaller\")\n",
    "print(f\" - is {baseline_time/small_time:.2f} times faster\")\n",
    "\n",
    "student_time = predict(student_model, \"student_submission.csv\")\n",
    "student_size = size(student_path)\n",
    "student_parameters = count_parameters(student_model)\n",
    "print(f\"The student model:\") \n",
    "print(f\" - has {(student_parameters/baseline_parameters)*100:.2f}% of parameters\")\n",
    "print(f\" - is {baseline_size/student_size:.2f} times smaller\")\n",
    "print(f\" - is {baseline_time/student_time:.2f} times faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(model,dataloader):\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader):\n",
    "            inputs = data[0].to(device)\n",
    "            model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Earth_Observation/lib/python3.10/site-packages/torch/ao/quantization/observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "num_classes = 4\n",
    "baseline_model = models.resnet50(weights=None)\n",
    "baseline_model.fc = nn.Linear(baseline_model.fc.in_features, num_classes)\n",
    "baseline_model.load_state_dict(torch.load(model50_path))\n",
    "baseline_model.to(device)\n",
    "\n",
    "baseline_time = predict(baseline_model, \"baseline_submission.csv\")\n",
    "baseline_size = size(model50_path)\n",
    "baseline_parameters = count_parameters(baseline_model)\n",
    "\n",
    "quantized_path = \"./quantized_model\"\n",
    "\n",
    "quantized_model=models.quantization.resnet50()\n",
    "quantized_model.fc = nn.Linear(quantized_model.fc.in_features, num_classes)\n",
    "quantized_model.load_state_dict(torch.load(model50_path))\n",
    "quantized_model.to(device)\n",
    "quantized_model.eval()\n",
    "\n",
    "quantized_model.qconfig = torch.quantization.get_default_qconfig(\"x86\")\n",
    "quantized_model.fuse_model(is_qat=False)\n",
    "torch.quantization.prepare(quantized_model,inplace=True)\n",
    "\n",
    "cal(quantized_model,train_dataloader)\n",
    "\n",
    "quantized_model.eval()\n",
    "torch.quantization.convert(quantized_model,inplace=True)\n",
    "\n",
    "torch.save(quantized_model.state_dict(), quantized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantized model:\n",
      " - has 0.00% of parameters\n",
      " - is 3.91 times smaller\n",
      " - is 3.41 times faster\n"
     ]
    }
   ],
   "source": [
    "quantized_time = predict(quantized_model, \"quantized_submission.csv\")\n",
    "quantized_size = size(quantized_path)\n",
    "quantized_parameters = count_parameters(quantized_model)\n",
    "print(f\"The quantized model:\") \n",
    "print(f\" - has {(quantized_parameters/baseline_parameters)*100:.2f}% of parameters\")\n",
    "print(f\" - is {baseline_size/quantized_size:.2f} times smaller\")\n",
    "print(f\" - is {baseline_time/quantized_time:.2f} times faster\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
