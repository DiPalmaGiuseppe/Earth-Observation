{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth Observation - Land Classification on EuroSAT dataset\n",
    "\n",
    "* EuroSAT is a large-scale land use and land cover classification dataset derived from multispectral Sentinel-2 satellite imagery covering European continent. \n",
    "\n",
    "* EuroSAT is composed of 27,000 georeferenced image patches (64 x 64 pixels) - each patch comprises 13 spectral bands (optical through to shortwave infrared ) resampled to 10m spatila resolution and labelled with one of 10 distinct land cover classes: AnnualCrop, Forest, HerbaceousVegetation, Highway, Industrial, Pasture, PermanentCrop, Residential, River, SeaLake. \n",
    "\n",
    "* Full details including links to journal papers and download instructions may be found here: https://github.com/phelber/eurosat.\n",
    "\n",
    "![alt text](https://github.com/phelber/EuroSAT/blob/master/eurosat_overview_small.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Setup Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import EuroSAT\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torch.optim.lr_scheduler import MultiStepLR, CosineAnnealingWarmRestarts\n",
    "from avalanche.benchmarks.datasets import default_dataset_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configure settings for the corresponding optimizers and schedulers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_path = './teacher'\n",
    "pretrained_student_path = './pretrained_student'\n",
    "student_path = './student'\n",
    "small_path = './small'\n",
    "\n",
    "use_AdamW = True # Flag utilized for switching between AdamW and SGD optimizer.\n",
    "\n",
    "if use_AdamW:\n",
    "  config = {'train_test_split':0.1, # train test split ratio\n",
    "            'tr_val_split':0.2, # train validation split ratio\n",
    "            'seed':42, # random seed\n",
    "            'mini_batch_size':128,\n",
    "            'epochs':20,\n",
    "            \n",
    "            # Settings for the optimizer AdamW\n",
    "            'lr':5e-4, # learning rate\n",
    "            'weight_decay':5e-4,\n",
    "\n",
    "            # Settings for the lr_scheduler CosineAnnealingWarmRestarts\n",
    "            't_0':5, # Number of iterations for the first restart.\n",
    "            'eta_min':1e-5, # Minimum learning rate\n",
    "          }\n",
    "else:\n",
    "  config = {'train_test_split':0.1, # train test split ratio\n",
    "            'tr_val_split':0.2, # train validation split ratio\n",
    "            'seed':42, # random seed\n",
    "            'mini_batch_size':128,\n",
    "            'epochs':100,\n",
    "\n",
    "            # Settings for the optimizer SGD\n",
    "            'lr':1e-4, # learning rate\n",
    "            'weight_decay':5e-4,  \n",
    "            'momentum':0.9,\n",
    "\n",
    "            # Settings for the lr_scheduler MultiStepLR\n",
    "            'milestones':[50,75,90], # List of epoch indices.\n",
    "            'gamma':0.2, # Multiplicative factor of learning rate decay.\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define a function to set a random seed for reproducibility assurance:\n",
    "* Manage sources of randomness that may lead to varying behaviors in multiple executions of your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=42):\n",
    "    random.seed(seed) # set python seed\n",
    "    np.random.seed(seed) # seed the global NumPy random number generator(RNG)\n",
    "    torch.manual_seed(seed) # seed the RNG for all devices(both CPU and CUDA) \n",
    "\n",
    "set_random_seed(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Tracks the active GPU and allocates all new CUDA tensors on that device by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preparing the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform pipeline\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Dataset download\n",
    "ssl._create_default_https_context = ssl._create_unverified_context # Turn off the ssl verification.\n",
    "dataset_path = default_dataset_location(\"eurosat\")\n",
    "dataset = EuroSAT(root=dataset_path, transform=transform, download=True)\n",
    "\n",
    "# Train/Test split\n",
    "n = int(len(dataset) * (1 - config['train_test_split']))\n",
    "eurosat_train, eurosat_test = torch.utils.data.random_split(dataset, [n, len(dataset) - n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 20952 's label : 6 PermanentCrop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9be9c37520>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly select an image from the Training Data for visualization and print its corresponding label.\n",
    "classes = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
    "random_index = random.randrange(len(eurosat_train)) # random select an index\n",
    "random_image = eurosat_train[random_index][0].numpy().transpose((1, 2, 0))\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "random_image = std * random_image + mean\n",
    "random_image = np.clip(random_image, 0, 1)\n",
    "print(\"Image\", random_index, \"'s label :\", eurosat_train[random_index][1], classes[eurosat_train[random_index][1]])\n",
    "plt.imshow(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Instantiate PyTorch data loader that feeds the image tensors to our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tr/Val split\n",
    "n = int(len(eurosat_train) * config['tr_val_split'])\n",
    "eurosat_tr, eurosat_val = torch.utils.data.random_split(eurosat_train, [n, len(eurosat_train) - n])\n",
    "\n",
    "# instantiate data loaders\n",
    "train_dataloader = torch.utils.data.DataLoader(eurosat_tr, batch_size=config['mini_batch_size'], shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(eurosat_val, batch_size=config['mini_batch_size'], shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(eurosat_test, batch_size=config['mini_batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create a ResNet-50 model using torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "# https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html\n",
    "teacher_model = models.resnet50(weights='DEFAULT')\n",
    "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, num_classes)\n",
    "teacher_model.to(device)\n",
    "\n",
    "pretrained_student_model = models.resnet34(weights=\"DEFAULT\")\n",
    "pretrained_student_model.fc= nn.Linear(pretrained_student_model.fc.in_features, num_classes)\n",
    "pretrained_student_model.to(device)\n",
    "\n",
    "student_model = models.resnet34()\n",
    "student_model.fc= nn.Linear(student_model.fc.in_features, num_classes)\n",
    "student_model.to(device)\n",
    "\n",
    "small_model = models.resnet34(weights=\"DEFAULT\")\n",
    "small_model.fc= nn.Linear(small_model.fc.in_features, num_classes)\n",
    "small_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Define the Training Loop\n",
    "Below, we have a function that performs one training epoch. It enumerates data from the DataLoader, and on each pass of the loop does the following:\n",
    "\n",
    "* Gets a batch of training data from the DataLoader\n",
    "\n",
    "* Zeros the optimizer’s gradients\n",
    "\n",
    "* Performs an inference - that is, gets predictions from the model for an input batch\n",
    "\n",
    "* Calculates the loss for that set of predictions vs. the labels on the dataset\n",
    "\n",
    "* Calculates the backward gradients over the learning weights\n",
    "\n",
    "* Tells the optimizer to perform one learning step - that is, adjust the model’s learning weights based on the observed gradients for this batch, according to the optimization algorithm we chose\n",
    "\n",
    "* Finally, it reports the averaged epoch loss for comparison with a validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,optimizer,epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for _, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.to(device))\n",
    "\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predictions = outputs.max(dim=-1)\n",
    "        num_correct += (predictions == labels.to(device)).sum()\n",
    "        num_samples += predictions.size(0)\n",
    "        \n",
    "    train_loss = running_loss/len(train_dataloader)\n",
    "    train_acc = float(num_correct)/float(num_samples)\n",
    "\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def train(model,model_path):\n",
    "\n",
    "    path=model_path[1:]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d')\n",
    "    writer = SummaryWriter('./{}{}'.format(timestamp,path))\n",
    "    epoch_number = 0\n",
    "    tr_acc = 0.0\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        print('============= EPOCH {} ============='.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss, tr_acc = train_one_epoch(model,optimizer,epoch_number, writer)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        val_acc = 0.0\n",
    "        num_vcorrect = 0\n",
    "        num_vsamples = 0\n",
    "\n",
    "        # Set the model to evaluation mode, disabling dropout and using population statistics for batch normalization.\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_dataloader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs.to(device))\n",
    "                vloss = criterion(voutputs, vlabels.to(device))\n",
    "                running_vloss += vloss\n",
    "                _, vpredictions = voutputs.max(dim=-1)\n",
    "                num_vcorrect += (vpredictions == vlabels.to(device)).sum()\n",
    "                num_vsamples += vpredictions.size(0)\n",
    "\n",
    "        avg_vloss = running_vloss / len(val_dataloader)\n",
    "        val_acc = float(num_vcorrect)/float(num_vsamples)\n",
    "        print('LOSS : train {} | valid {}'.format(round(avg_loss, 4), round(avg_vloss.item(), 4)))\n",
    "        print('ACC  : train {}% | valid {}%'.format(round(tr_acc*100, 2), round(val_acc*100),2))\n",
    "\n",
    "        # Log the running loss averaged per epoch for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.add_scalars('Training vs. Validation Accuracy',\n",
    "                        { 'Training' : tr_acc, 'Validation' : val_acc },\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        epoch_number += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Train Teacher and Student\n",
    "* we also train the student to its performance without any specific process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training Teacher Model <--\n",
      "============= EPOCH 1 =============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS : train 0.5302 | valid 0.4309\n",
      "ACC  : train 84.2% | valid 88%\n",
      "============= EPOCH 2 =============\n",
      "LOSS : train 0.148 | valid 0.287\n",
      "ACC  : train 95.47% | valid 91%\n",
      "============= EPOCH 3 =============\n",
      "LOSS : train 0.0749 | valid 0.2526\n",
      "ACC  : train 97.74% | valid 93%\n",
      "============= EPOCH 4 =============\n",
      "LOSS : train 0.06 | valid 0.2606\n",
      "ACC  : train 98.05% | valid 93%\n",
      "============= EPOCH 5 =============\n",
      "LOSS : train 0.0623 | valid 0.2287\n",
      "ACC  : train 98.07% | valid 94%\n",
      "============= EPOCH 6 =============\n",
      "LOSS : train 0.0669 | valid 0.2142\n",
      "ACC  : train 97.84% | valid 94%\n",
      "============= EPOCH 7 =============\n",
      "LOSS : train 0.0576 | valid 0.1722\n",
      "ACC  : train 98.48% | valid 95%\n",
      "============= EPOCH 8 =============\n",
      "LOSS : train 0.0382 | valid 0.3495\n",
      "ACC  : train 98.91% | valid 91%\n",
      "============= EPOCH 9 =============\n",
      "LOSS : train 0.045 | valid 0.2911\n",
      "ACC  : train 98.85% | valid 94%\n",
      "============= EPOCH 10 =============\n",
      "LOSS : train 0.0642 | valid 0.237\n",
      "ACC  : train 98.4% | valid 94%\n",
      "============= EPOCH 11 =============\n",
      "LOSS : train 0.0452 | valid 0.2545\n",
      "ACC  : train 98.64% | valid 93%\n",
      "============= EPOCH 12 =============\n",
      "LOSS : train 0.0416 | valid 0.459\n",
      "ACC  : train 98.95% | valid 91%\n",
      "============= EPOCH 13 =============\n",
      "LOSS : train 0.0365 | valid 0.3222\n",
      "ACC  : train 98.93% | valid 92%\n",
      "============= EPOCH 14 =============\n",
      "LOSS : train 0.0246 | valid 0.2139\n",
      "ACC  : train 99.36% | valid 94%\n",
      "============= EPOCH 15 =============\n",
      "LOSS : train 0.0211 | valid 0.2308\n",
      "ACC  : train 99.3% | valid 94%\n",
      "============= EPOCH 16 =============\n",
      "LOSS : train 0.0125 | valid 0.4783\n",
      "ACC  : train 99.65% | valid 91%\n",
      "============= EPOCH 17 =============\n",
      "LOSS : train 0.0167 | valid 0.7431\n",
      "ACC  : train 99.51% | valid 88%\n",
      "============= EPOCH 18 =============\n",
      "LOSS : train 0.0308 | valid 0.2293\n",
      "ACC  : train 99.09% | valid 94%\n",
      "============= EPOCH 19 =============\n",
      "LOSS : train 0.026 | valid 0.242\n",
      "ACC  : train 99.2% | valid 94%\n",
      "============= EPOCH 20 =============\n",
      "LOSS : train 0.0158 | valid 0.4818\n",
      "ACC  : train 99.55% | valid 88%\n",
      "\n",
      "--> Training Small Model <--\n",
      "============= EPOCH 1 =============\n",
      "LOSS : train 0.6112 | valid 0.5023\n",
      "ACC  : train 81.79% | valid 87%\n",
      "============= EPOCH 2 =============\n",
      "LOSS : train 0.2261 | valid 0.3433\n",
      "ACC  : train 92.96% | valid 90%\n",
      "============= EPOCH 3 =============\n",
      "LOSS : train 0.1516 | valid 0.3351\n",
      "ACC  : train 95.16% | valid 90%\n",
      "============= EPOCH 4 =============\n",
      "LOSS : train 0.1155 | valid 0.5638\n",
      "ACC  : train 96.36% | valid 85%\n",
      "============= EPOCH 5 =============\n",
      "LOSS : train 0.0869 | valid 0.3313\n",
      "ACC  : train 97.39% | valid 91%\n",
      "============= EPOCH 6 =============\n",
      "LOSS : train 0.0763 | valid 0.4823\n",
      "ACC  : train 97.55% | valid 86%\n",
      "============= EPOCH 7 =============\n",
      "LOSS : train 0.0869 | valid 0.5348\n",
      "ACC  : train 96.91% | valid 86%\n",
      "============= EPOCH 8 =============\n",
      "LOSS : train 0.0589 | valid 0.9965\n",
      "ACC  : train 98.07% | valid 77%\n",
      "============= EPOCH 9 =============\n",
      "LOSS : train 0.0629 | valid 0.3577\n",
      "ACC  : train 98.09% | valid 90%\n",
      "============= EPOCH 10 =============\n",
      "LOSS : train 0.0664 | valid 0.41\n",
      "ACC  : train 97.86% | valid 90%\n",
      "============= EPOCH 11 =============\n",
      "LOSS : train 0.0408 | valid 0.246\n",
      "ACC  : train 98.81% | valid 93%\n",
      "============= EPOCH 12 =============\n",
      "LOSS : train 0.0258 | valid 0.2964\n",
      "ACC  : train 99.16% | valid 92%\n",
      "============= EPOCH 13 =============\n",
      "LOSS : train 0.0391 | valid 0.6017\n",
      "ACC  : train 98.72% | valid 85%\n",
      "============= EPOCH 14 =============\n",
      "LOSS : train 0.0549 | valid 0.6195\n",
      "ACC  : train 98.48% | valid 85%\n",
      "============= EPOCH 15 =============\n",
      "LOSS : train 0.0604 | valid 0.3826\n",
      "ACC  : train 98.27% | valid 90%\n",
      "============= EPOCH 16 =============\n",
      "LOSS : train 0.0479 | valid 0.3577\n",
      "ACC  : train 98.79% | valid 91%\n",
      "============= EPOCH 17 =============\n",
      "LOSS : train 0.0247 | valid 0.3094\n",
      "ACC  : train 99.09% | valid 93%\n",
      "============= EPOCH 18 =============\n",
      "LOSS : train 0.0406 | valid 0.4772\n",
      "ACC  : train 98.7% | valid 89%\n",
      "============= EPOCH 19 =============\n",
      "LOSS : train 0.0485 | valid 0.403\n",
      "ACC  : train 98.52% | valid 90%\n",
      "============= EPOCH 20 =============\n",
      "LOSS : train 0.0282 | valid 0.9311\n",
      "ACC  : train 99.05% | valid 81%\n"
     ]
    }
   ],
   "source": [
    "print(\"--> Training Teacher Model <--\")\n",
    "train(teacher_model,teacher_path)\n",
    "print(\"\\n--> Training Small Model <--\")\n",
    "train(small_model,small_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Define Distillation Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knowledge_distillation(teacher, student, T, soft_target_loss_weight, ce_loss_weight, device,student_path):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(student.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    teacher.eval()  # Teacher set to evaluation mode\n",
    "\n",
    "    tr_acc = 0.0\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        student.train() # Student to train mode\n",
    "\n",
    "        print('============= EPOCH {} ============='.format(epoch + 1))\n",
    "\n",
    "        running_loss = 0.\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        running_vloss = 0.0\n",
    "        val_acc = 0.0\n",
    "        num_vcorrect = 0\n",
    "        num_vsamples = 0\n",
    "\n",
    "        for _, data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "            # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predictions = student_logits.max(dim=-1)\n",
    "\n",
    "            num_correct += (predictions == labels.to(device)).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        avg_loss = running_loss/len(train_dataloader)\n",
    "        tr_acc = float(num_correct)/float(num_samples)\n",
    "            # Set the model to evaluation mode, disabling dropout and using population statistics for batch normalization.\n",
    "\n",
    "        student.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_dataloader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = student(vinputs.to(device))\n",
    "                vloss = criterion(voutputs, vlabels.to(device))\n",
    "                running_vloss += vloss\n",
    "                _, vpredictions = voutputs.max(dim=-1)\n",
    "                num_vcorrect += (vpredictions == vlabels.to(device)).sum()\n",
    "                num_vsamples += vpredictions.size(0)\n",
    "\n",
    "        avg_vloss = running_vloss / len(val_dataloader)\n",
    "        val_acc = float(num_vcorrect)/float(num_vsamples)\n",
    "        print('LOSS : train {} | valid {}'.format(round(avg_loss, 4), round(avg_vloss.item(), 4)))\n",
    "        print('ACC  : train {}% | valid {}%'.format(round(tr_acc*100, 2), round(val_acc*100),2))\n",
    "\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            torch.save(student.state_dict(), student_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Student training\n",
    "*  train of two students, one with no pretrained weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= EPOCH 1 =============\n",
      "LOSS : train 0.7094 | valid 0.7052\n",
      "ACC  : train 85.6% | valid 83%\n",
      "============= EPOCH 2 =============\n",
      "LOSS : train 0.5286 | valid 0.5129\n",
      "ACC  : train 94.38% | valid 89%\n",
      "============= EPOCH 3 =============\n",
      "LOSS : train 0.4869 | valid 0.6604\n",
      "ACC  : train 95.99% | valid 83%\n",
      "============= EPOCH 4 =============\n",
      "LOSS : train 0.4833 | valid 0.4782\n",
      "ACC  : train 96.26% | valid 91%\n",
      "============= EPOCH 5 =============\n",
      "LOSS : train 0.4606 | valid 0.4413\n",
      "ACC  : train 97.74% | valid 92%\n",
      "============= EPOCH 6 =============\n",
      "LOSS : train 0.449 | valid 0.4508\n",
      "ACC  : train 97.92% | valid 91%\n",
      "============= EPOCH 7 =============\n",
      "LOSS : train 0.4514 | valid 0.4731\n",
      "ACC  : train 97.98% | valid 92%\n",
      "============= EPOCH 8 =============\n",
      "LOSS : train 0.4504 | valid 0.3965\n",
      "ACC  : train 98.02% | valid 93%\n",
      "============= EPOCH 9 =============\n",
      "LOSS : train 0.4272 | valid 0.4143\n",
      "ACC  : train 99.03% | valid 93%\n",
      "============= EPOCH 10 =============\n",
      "LOSS : train 0.4289 | valid 0.4105\n",
      "ACC  : train 98.93% | valid 93%\n",
      "============= EPOCH 11 =============\n",
      "LOSS : train 0.4318 | valid 0.4944\n",
      "ACC  : train 98.81% | valid 90%\n",
      "============= EPOCH 12 =============\n",
      "LOSS : train 0.4252 | valid 0.388\n",
      "ACC  : train 99.14% | valid 94%\n",
      "============= EPOCH 13 =============\n",
      "LOSS : train 0.4164 | valid 0.3859\n",
      "ACC  : train 99.51% | valid 94%\n",
      "============= EPOCH 14 =============\n",
      "LOSS : train 0.4125 | valid 0.6316\n",
      "ACC  : train 99.79% | valid 85%\n",
      "============= EPOCH 15 =============\n",
      "LOSS : train 0.4206 | valid 0.4845\n",
      "ACC  : train 99.34% | valid 91%\n",
      "============= EPOCH 16 =============\n",
      "LOSS : train 0.4216 | valid 0.3881\n",
      "ACC  : train 99.2% | valid 94%\n",
      "============= EPOCH 17 =============\n",
      "LOSS : train 0.4159 | valid 0.3606\n",
      "ACC  : train 99.61% | valid 95%\n",
      "============= EPOCH 18 =============\n",
      "LOSS : train 0.4184 | valid 0.4998\n",
      "ACC  : train 99.42% | valid 90%\n",
      "============= EPOCH 19 =============\n",
      "LOSS : train 0.4168 | valid 0.4532\n",
      "ACC  : train 99.44% | valid 91%\n",
      "============= EPOCH 20 =============\n",
      "LOSS : train 0.4223 | valid 0.4288\n",
      "ACC  : train 99.2% | valid 93%\n",
      "============= EPOCH 1 =============\n",
      "LOSS : train 1.2922 | valid 2.7415\n",
      "ACC  : train 50.45% | valid 21%\n",
      "============= EPOCH 2 =============\n",
      "LOSS : train 1.0211 | valid 1.0052\n",
      "ACC  : train 64.92% | valid 69%\n",
      "============= EPOCH 3 =============\n",
      "LOSS : train 0.9417 | valid 1.3201\n",
      "ACC  : train 69.32% | valid 58%\n",
      "============= EPOCH 4 =============\n",
      "LOSS : train 0.8711 | valid 1.0685\n",
      "ACC  : train 73.58% | valid 68%\n",
      "============= EPOCH 5 =============\n",
      "LOSS : train 0.8606 | valid 0.9692\n",
      "ACC  : train 75.45% | valid 70%\n",
      "============= EPOCH 6 =============\n",
      "LOSS : train 0.8131 | valid 1.0996\n",
      "ACC  : train 77.08% | valid 64%\n",
      "============= EPOCH 7 =============\n",
      "LOSS : train 0.7753 | valid 0.899\n",
      "ACC  : train 79.59% | valid 74%\n",
      "============= EPOCH 8 =============\n",
      "LOSS : train 0.753 | valid 1.6635\n",
      "ACC  : train 81.28% | valid 50%\n",
      "============= EPOCH 9 =============\n",
      "LOSS : train 0.7313 | valid 1.2784\n",
      "ACC  : train 82.16% | valid 61%\n",
      "============= EPOCH 10 =============\n",
      "LOSS : train 0.7026 | valid 0.9727\n",
      "ACC  : train 83.72% | valid 70%\n",
      "============= EPOCH 11 =============\n",
      "LOSS : train 0.6649 | valid 0.723\n",
      "ACC  : train 85.7% | valid 81%\n",
      "============= EPOCH 12 =============\n",
      "LOSS : train 0.6647 | valid 0.8321\n",
      "ACC  : train 85.78% | valid 77%\n",
      "============= EPOCH 13 =============\n",
      "LOSS : train 0.6425 | valid 0.9743\n",
      "ACC  : train 87.49% | valid 72%\n",
      "============= EPOCH 14 =============\n",
      "LOSS : train 0.6117 | valid 1.0187\n",
      "ACC  : train 89.22% | valid 68%\n",
      "============= EPOCH 15 =============\n",
      "LOSS : train 0.585 | valid 1.1969\n",
      "ACC  : train 90.74% | valid 66%\n",
      "============= EPOCH 16 =============\n",
      "LOSS : train 0.5929 | valid 0.7444\n",
      "ACC  : train 90.23% | valid 80%\n",
      "============= EPOCH 17 =============\n",
      "LOSS : train 0.5485 | valid 0.9277\n",
      "ACC  : train 92.78% | valid 73%\n",
      "============= EPOCH 18 =============\n",
      "LOSS : train 0.5296 | valid 0.8343\n",
      "ACC  : train 93.91% | valid 77%\n",
      "============= EPOCH 19 =============\n",
      "LOSS : train 0.5183 | valid 1.0359\n",
      "ACC  : train 94.36% | valid 71%\n",
      "============= EPOCH 20 =============\n",
      "LOSS : train 0.5131 | valid 0.8981\n",
      "ACC  : train 94.77% | valid 75%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
    "train_knowledge_distillation(teacher=teacher_model, student=pretrained_student_model, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device,student_path=pretrained_student_path)\n",
    "train_knowledge_distillation(teacher=teacher_model, student=student_model, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device,student_path=student_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model evaluation on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = models.resnet50(weights='DEFAULT')\n",
    "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, num_classes)\n",
    "teacher_model.load_state_dict(torch.load(teacher_path))\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()\n",
    "\n",
    "pretrained_student_model = models.resnet34(weights=\"DEFAULT\")\n",
    "pretrained_student_model.fc= nn.Linear(pretrained_student_model.fc.in_features, num_classes)\n",
    "pretrained_student_model.load_state_dict(torch.load(pretrained_student_path))\n",
    "pretrained_student_model.to(device)\n",
    "pretrained_student_model.eval()\n",
    "\n",
    "student_model = models.resnet34()\n",
    "student_model.fc= nn.Linear(student_model.fc.in_features, num_classes)\n",
    "student_model.load_state_dict(torch.load(student_path))\n",
    "student_model.to(device)\n",
    "student_model.eval()\n",
    "\n",
    "small_model = models.resnet34(weights=\"DEFAULT\")\n",
    "small_model.fc= nn.Linear(small_model.fc.in_features, num_classes)\n",
    "small_model.load_state_dict(torch.load(small_path))\n",
    "small_model.to(device)\n",
    "small_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Define Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(model):\n",
    "    running_tloss = 0.\n",
    "    test_acc = 0.\n",
    "    num_tcorrect = 0\n",
    "    num_tsamples = 0\n",
    "    with torch.no_grad():\n",
    "        for _, tdata in enumerate(test_dataloader):\n",
    "            tinputs, tlabels = tdata\n",
    "            toutputs = model(tinputs.to(device))\n",
    "            tloss = criterion(toutputs, tlabels.to(device))\n",
    "            running_tloss += tloss\n",
    "            _, tpredictions = toutputs.max(dim=-1)\n",
    "            num_tcorrect += (tpredictions == tlabels.to(device)).sum()\n",
    "            num_tsamples += tpredictions.size(0)\n",
    "    avg_tloss = running_tloss/len(test_dataloader)\n",
    "    test_acc = float(num_tcorrect)/float(num_tsamples)\n",
    "    return avg_tloss,test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Evaluate the models on the Test Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Teacher (ResNet50) <---\n",
      "Loss: 0.152\n",
      "Accuracy: 95.07\n",
      "---> ResNet34 <---\n",
      "This are the performance of ResNet34 with no distillation process\n",
      "The students have the same model\n",
      "Loss: 0.2031\n",
      "Accuracy: 93.67\n",
      "---> Student <---\n",
      "Loss: 0.7089\n",
      "Accuracy: 80.96\n",
      "---> Pretrained Student <---\n",
      "Loss: 0.3558\n",
      "Accuracy: 94.67\n"
     ]
    }
   ],
   "source": [
    "print(f\"---> Teacher (ResNet50) <---\")\n",
    "teacher_avg_tloss, teacher_test_acc = eval_loop(teacher_model)\n",
    "print(f'Loss: {round(teacher_avg_tloss.item(),4)}')\n",
    "print(f'Accuracy: {round(teacher_test_acc*100,2)}')\n",
    "\n",
    "\n",
    "print(f\"---> ResNet34 <---\")\n",
    "print(f\"This are the performance of ResNet34 with no distillation process\")\n",
    "print(f\"The students have the same model\")\n",
    "small_model_avg_tloss, small_model_test_acc = eval_loop(small_model) \n",
    "print(f'Loss: {round(small_model_avg_tloss.item(),4)}')\n",
    "print(f'Accuracy: {round(small_model_test_acc*100,2)}')\n",
    "\n",
    "\n",
    "print(f\"---> Student <---\")\n",
    "teacher_avg_tloss, teacher_test_acc = eval_loop(student_model)\n",
    "print(f'Loss: {round(teacher_avg_tloss.item(),4)}')\n",
    "print(f'Accuracy: {round(teacher_test_acc*100,2)}')\n",
    "\n",
    "\n",
    "print(f\"---> Pretrained Student <---\")\n",
    "teacher_avg_tloss, teacher_test_acc = eval_loop(pretrained_student_model)\n",
    "print(f'Loss: {round(teacher_avg_tloss.item(),4)}')\n",
    "print(f'Accuracy: {round(teacher_test_acc*100,2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
